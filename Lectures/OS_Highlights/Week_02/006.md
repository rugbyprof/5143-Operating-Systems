---
marp: true
theme: border
paginate: true
header: "ğŸ´ MSU OpSys"
footer: "Producerâ€“Consumer Problem â€” Griffin | GPT-5"
style: |
  h1, h2, h3 { color: #7a0019; }
  pre, code { font-size: 0.9em; }
  .gold { color: #ffcc33; }
---

# ğŸ­ The Producerâ€“Consumer Problem

> â€œTwo threads walk into a buffer. One adds, one removes.
> Chaos ensues â€” unless you synchronize.â€

---

## ğŸ’¡ Scenario

- One or more **producers** generate data (items, tasks, messages).
- One or more **consumers** process that data.
- They share a **finite buffer**.

We must ensure:

1. Producers donâ€™t overflow the buffer (no overfilling).
2. Consumers donâ€™t underflow it (no empty reads).
3. Access is synchronized.

---

## ğŸ§© Imports and Setup

```python
import threading, time, random

BUFFER_SIZE = 5
buffer = []
lock = threading.Lock()
```

---

## âš ï¸ Attempt #1 â€“ The NaÃ¯ve Version

```python
def producer():
    global buffer
    while True:
        item = random.randint(1, 100)
        buffer.append(item)
        print(f"Produced {item} (size={len(buffer)})")
        time.sleep(random.uniform(0.2, 0.6))

def consumer():
    global buffer
    while True:
        if buffer:
            item = buffer.pop(0)
            print(f"Consumed {item} (size={len(buffer)})")
        time.sleep(random.uniform(0.3, 0.7))
```

ğŸ’¥ **Race conditions** everywhere!

- Two threads could access `buffer` simultaneously.
- Consumer might pop from an empty list â†’ `IndexError`.
- Producer might flood buffer â†’ memory balloon.

---

## ğŸ§± Attempt #2 â€“ Add Locks (But Poorly)

```python
def producer():
    while True:
        with lock:
            item = random.randint(1, 100)
            buffer.append(item)
            print(f"Produced {item} (size={len(buffer)})")
        time.sleep(random.uniform(0.2, 0.6))

def consumer():
    while True:
        with lock:
            if buffer:
                item = buffer.pop(0)
                print(f"Consumed {item} (size={len(buffer)})")
        time.sleep(random.uniform(0.3, 0.7))
```

âœ… Prevents simultaneous access
âŒ Still **no coordination**:

- Producer might overfill.
- Consumer might spin forever waiting on emptiness.
- Threads waste CPU cycles.

---

## ğŸš¦ Attempt #3 â€“ Use Semaphores (Bounded Buffer)

```python
empty = threading.Semaphore(BUFFER_SIZE)
full = threading.Semaphore(0)

def producer():
    while True:
        item = random.randint(1, 100)
        empty.acquire()        # wait for an empty slot
        with lock:
            buffer.append(item)
            print(f"Produced {item} (size={len(buffer)})")
        full.release()         # signal that buffer has an item
        time.sleep(random.uniform(0.2, 0.6))

def consumer():
    while True:
        full.acquire()         # wait for an item
        with lock:
            item = buffer.pop(0)
            print(f"Consumed {item} (size={len(buffer)})")
        empty.release()        # signal that slot is free
        time.sleep(random.uniform(0.3, 0.7))
```

âœ… Classic bounded-buffer solution
âœ… No deadlock
âœ… No busy waiting
âš™ï¸ Perfect conceptual model for OS process scheduling, I/O queues, etc.

---

## âš™ï¸ Main Function (for all working versions)

```python
def main():
    threads = []
    t1 = threading.Thread(target=producer, daemon=True)
    t2 = threading.Thread(target=consumer, daemon=True)
    threads.extend([t1, t2])

    for t in threads: t.start()
    time.sleep(10)
    print("Simulation complete.")
```

Run it once and watch alternating â€œProducedâ€ and â€œConsumedâ€ messages.

---

## ğŸ§° Attempt #4 â€“ Pythonic Queue (Modern Approach)

```python
from queue import Queue

q = Queue(maxsize=BUFFER_SIZE)

def producer():
    while True:
        item = random.randint(1, 100)
        q.put(item)  # blocks if full
        print(f"Produced {item} (size={q.qsize()})")
        time.sleep(random.uniform(0.2, 0.6))

def consumer():
    while True:
        item = q.get()  # blocks if empty
        print(f"Consumed {item} (size={q.qsize()})")
        q.task_done()
        time.sleep(random.uniform(0.3, 0.7))
```

âœ… Thread-safe
âœ… No manual semaphore or lock juggling
âœ… Ideal for real Python systems
ğŸ’¬ Teaching point: _abstraction beats micromanagement._

---

## ğŸ§  Summary Table

| Approach   | Race Safety | Busy Waiting | Bounded | Ease     | Notes            |
| ---------- | ----------- | ------------ | ------- | -------- | ---------------- |
| NaÃ¯ve      | âŒ          | ğŸ˜µ           | âŒ      | Easy     | Everything wrong |
| Lock Only  | âœ…          | ğŸ˜¬           | âŒ      | Moderate | No coordination  |
| Semaphores | âœ…          | âœ…           | âœ…      | Medium   | Textbook OS      |
| Queue      | âœ…          | âœ…           | âœ…      | ğŸ¤“       | Idiomatic Python |

---

## ğŸ§© OS Concepts Mapped

| OS Concept | Analogy                                 |
| ---------- | --------------------------------------- |
| Producer   | I/O device writing data                 |
| Consumer   | CPU reading/processing                  |
| Buffer     | Shared memory or disk queue             |
| Semaphore  | OS kernel synchronization primitive     |
| Queue      | Abstracted thread-safe resource manager |

---

## âš–ï¸ Discussion Prompts

1. What would happen if we reversed `full` and `empty` order?
2. Why is it important that the semaphores are initialized correctly?
3. How would this differ if there were **multiple producers** or **multiple consumers**?
4. What happens if the consumer processes much slower than producer?

---

## ğŸ Takeaway

> â€œThe Producerâ€“Consumer problem isnâ€™t about milk and cookies.
> Itâ€™s about **respecting shared space** and taking turns like civilized threads.â€
