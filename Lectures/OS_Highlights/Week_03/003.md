---
marp: true
theme: border
paginate: true
header: "ğŸ´ MSU OpSys"
# footer: "What is an OS Really Doing (scaffolding with OpenAI GPT-5)"
# style: ../assets/msu-theme.css
style:
  section {
    font-size: 0.8em; /* shrink all slide text slightly */
  }
  pre code {
    font-size: 0.6em;
  }
---
# ğŸ§© **3. Caching, TLBs, Buffering & I/O Hierarchy**

---

## âš¡ **Why Caching Exists**

- Memory is **orders of magnitude** slower than the CPU.  
- Disk is **orders of magnitude** slower than memory.

Hierarchy:

```
Registers
  â†“
L1 cache (nanoseconds)
  â†“
L2/L3 cache
  â†“
RAM (hundreds of ns)
  â†“
SSD (micro/milliseconds)
  â†“
HDD (milliseconds)
```

> **Caches exist because going to RAM for everything is like going to your car for every pen stroke.**

---

## ğŸ§  **Locality: The OSâ€™s Favorite Trick**

Programs tend to use:

- the same data repeatedly (**temporal locality**)
- data near other data (**spatial locality**)

Caches exploit this to speed things up.

---

## ğŸ—‚ï¸ **CPU Caches (L1, L2, L3)** â€” High-Level Only

Designed to:

- store recent memory accesses
- detect patterns
- prefetch likely-needed data
- avoid RAM accesses when possible

This is COMPLETELY implemented in hardware.  
Your OS just tries not to get in the way.

---

## ğŸš€ **TLB (Translation Lookaside Buffer)**

Problem:  
Page tables are in memory â†’ slow lookups

Solution:  
TLB caches **page table entries**.

If a page translation is in the TLB â†’ instant  
If not â†’ â€œTLB missâ€ â†’ slower memory lookup

> **Analogy:** TLB = your browserâ€™s DNS cache.  
> Without it, every page load becomes pain.

---

## ğŸ“¦ **Buffers and I/O Queues**

Filesystems use buffers to:

- smooth out bursty disk access
- batch reads/writes
- handle reordering
- improve throughput

You donâ€™t want to hit the disk for every byte, so:

- writes go into buffers
- OS flushes them later
- read-ahead preloads likely future blocks

> **Think: streaming platforms buffering content so your show doesnâ€™t freeze every 200 ms.**

---

## ğŸ’½ **The File I/O Journey (Conceptual)**

```
Your program
     â†“ write()
Kernel buffers
     â†“ flush / schedule
Disk driver
     â†“
SSD/HDD
```

At each step:

- something is cached
- something is queued
- something is optimized

Which is why â€œsaving a fileâ€ might not hit disk immediately.

---

## ğŸ§ª **SSD Behavior (High-Level)**

Challenges for SSDs:

- flash memory wears out
- need wear leveling
- internal garbage collection
- logical-to-physical mapping layer (FTL)
- unpredictable latency spikes

Thus, SSDs also use internal caching and translation.

---

## ğŸ¬ **Caches & Buffers Summary Slide**

- Caches hide latency
- Locality makes caching effective
- TLB caches page translations
- Buffers smooth disk I/O
- SSDs have invisible internal caching

---

If you want, next message will include:

### **Topic 4: File Systems (expanded)**

and

### **Topic 5: Modern Evolution (expanded)**

And if you want a **Marp slide deck** for all 5 topics, I can generate the whole thing slide-by-slide.
